{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWZw1OHBUyB-"
      },
      "source": [
        "# LangChainを用いて、昨日や一週間前のことを会話する\n",
        "\n",
        "もしマイ・チャットボットがいたら、当然、数日前の会話内容を覚えていて欲しいですよね？  \n",
        "以下では、過去の会話内容に基づいた会話をするチャットボットを、LangChainを用いて作っていきます。\n",
        "\n",
        "1. 環境構築\n",
        "2. 会話内容の保存・読込\n",
        "3. シンプルな方式（過去の会話を、文脈情報として与える）\n",
        "4. Agentを用いる方式（過去の会話を、ChatBot自身で呼び出す）\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6Ur8GXDYyqU"
      },
      "source": [
        "## 1. 環境構築"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ny_SaAYsUgD9",
        "outputId": "9f3d347f-1a8b-4e93-d544-5e6c096db239"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.228)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.16)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.5.9)\n",
            "Requirement already satisfied: langchainplus-sdk<0.0.21,>=0.0.20 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.20)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.9)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install openai langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e6b-N7qUZLPq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = 'PLEASE CHANGE HERE'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lZyfb4JY1l9"
      },
      "source": [
        "## 2. 会話内容の保存・読込"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JJEqHB_Zfd0"
      },
      "source": [
        "### LangChainでの会話内容の保存\n",
        "- LangChainでは、会話は`Memory`の内部に、`Message`のリストとして保存されます\n",
        "- 会話内容を`dict`型に変換する方法は、公式ページで紹介されています\n",
        "    - https://python.langchain.com/docs/modules/memory/#saving-message-history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkYyzcDGY4HJ",
        "outputId": "bc2be874-edf7-4ed4-b073-16e9d2ee7f86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'data': {'additional_kwargs': {}, 'content': 'hi!', 'example': False},\n",
            "  'type': 'human'},\n",
            " {'data': {'additional_kwargs': {}, 'content': 'whats up?', 'example': False},\n",
            "  'type': 'ai'}]\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.schema import messages_from_dict, messages_to_dict\n",
        "\n",
        "memory = ConversationBufferMemory(return_messages=True)\n",
        "memory.save_context({\"input\": \"hi!\"}, {\"output\": \"whats up?\"})\n",
        "\n",
        "chat_messages = memory.load_memory_variables({})['history']\n",
        "history_dict = messages_to_dict(chat_messages)\n",
        "pprint(history_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQnFH9fTcSdw"
      },
      "source": [
        "### 保存・読込用の関数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBlNFj9cauoD",
        "outputId": "95879052-df42-46b1-d37d-ac4e3c46dc2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved ... test_conversation.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': [HumanMessage(content='hi!', additional_kwargs={}, example=False),\n",
              "  AIMessage(content='whats up?', additional_kwargs={}, example=False)]}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# 会話内容の保存・読込の関数\n",
        "import json\n",
        "\n",
        "def save_conversation_from_memory(json_filepath, memory, memory_key='history', **kwargs):\n",
        "    history_messages = memory.load_memory_variables({})[memory_key]\n",
        "    history_dict = messages_to_dict(history_messages)\n",
        "    dat = dict({memory_key: history_dict}, **kwargs)  # 任意の情報を保存可能\n",
        "\n",
        "    with open(json_filepath, 'w') as fout:\n",
        "        json.dump(dat, fout)\n",
        "    print('Saved ...', json_filepath)\n",
        "\n",
        "def load_conversation_from_json(json_filepath, memory_key='history'):\n",
        "    with open(json_filepath, 'r') as fin:\n",
        "        dict_all = json.load(fin)\n",
        "        ret_dict = {}\n",
        "        for k, v in dict_all.items():\n",
        "            if k == memory_key:\n",
        "                ret_dict[k] = messages_from_dict(v)\n",
        "            else:\n",
        "                ret_dict[k] = v\n",
        "    return ret_dict\n",
        "\n",
        "json_file = 'test_conversation.json'\n",
        "save_conversation_from_memory(json_file, memory)\n",
        "load_conversation_from_json(json_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcAc1wkkcAeT"
      },
      "source": [
        "### 実験用に、会話内容を保存する"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "om0fw_mFco62",
        "outputId": "2c29eb5d-87e4-4bdc-8400-c799b066946d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved ... chat_history_20230628.json\n",
            "Saved ... chat_history_20230703.json\n",
            "Saved ... chat_history_20230704.json\n"
          ]
        }
      ],
      "source": [
        "# json_file, datetime, chat_history\n",
        "past_conversations = [\n",
        "    [\n",
        "        'chat_history_20230628.json',\n",
        "        '2023-06-28 19:03:42',\n",
        "        [\n",
        "            ({\"input\": \"最近暑くなってきたからさっぱりしたモノが食べたくて、冷麺を食べたよ。\"},\n",
        "             {\"output\": \"いいね！ちなみに、盛岡冷麺、韓国冷麺、どっち…？\"}),\n",
        "        ]\n",
        "    ],\n",
        "    [\n",
        "        'chat_history_20230703.json',\n",
        "        '2023-07-03 21:53:02',\n",
        "        [\n",
        "            ({\"input\": \"今日は友達とイタリアンに行ったよ。イカスミパスタと真鯛のカルパッチョを食べたんだけど、どっちも美味しかったぁ。\"},\n",
        "             {\"output\": \"いいなぁ。僕もイタリアン食べたい！！\"}),\n",
        "        ]\n",
        "    ],\n",
        "    [\n",
        "        'chat_history_20230704.json',\n",
        "        '2023-07-04 20:11:56',\n",
        "        [\n",
        "            ({\"input\": \"今日の昼は中華レストランでよだれ鶏を食べんたんだ。最近暑いからか、あの酸味と辛味を欲してしまうんだよね\"},\n",
        "             {\"output\": \"暑いと酸味と辛味を欲するの？なんで？\"}),\n",
        "        ]\n",
        "    ],\n",
        "]\n",
        "\n",
        "# 日別で会話内容を保存\n",
        "for json_file, datetime_str, chat_history in past_conversations:\n",
        "    memory = ConversationBufferMemory(return_messages=True)\n",
        "    for input_output_tuple in chat_history:\n",
        "        memory.save_context(*input_output_tuple)\n",
        "    # datetimeも一緒に保存\n",
        "    save_conversation_from_memory(json_file, memory, datetime=datetime_str)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgusHdNZY5AB"
      },
      "source": [
        "## 3. シンプルな方式\n",
        "過去の会話を、文脈情報として与える"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdgS2WQSY9xn",
        "outputId": "c7df9da8-9281-4124-a469-9d4bf47324f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "以下は、過去の会話です。\n",
            "================\n",
            "【日時】 2023-06-28 19:03:42\n",
            "Human: 最近暑くなってきたからさっぱりしたモノが食べたくて、冷麺を食べたよ。\n",
            "AI: いいね！ちなみに、盛岡冷麺、韓国冷麺、どっち…？\n",
            "---\n",
            "【日時】 2023-07-03 21:53:02\n",
            "Human: 今日は友達とイタリアンに行ったよ。イカスミパスタと真鯛のカルパッチョを食べたんだけど、どっちも美味しかったぁ。\n",
            "AI: いいなぁ。僕もイタリアン食べたい！！\n",
            "---\n",
            "【日時】 2023-07-04 20:11:56\n",
            "Human: 今日の昼は中華レストランでよだれ鶏を食べんたんだ。最近暑いからか、あの酸味と辛味を欲してしまうんだよね\n",
            "AI: 暑いと酸味と辛味を欲するの？なんで？\n",
            "================\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 過去の会話を読み込む\n",
        "import glob\n",
        "from langchain.schema import get_buffer_string  # Messageのリストを文字列に変換する関数\n",
        "\n",
        "\n",
        "def generate_context_from_past_chats(chat_history_files):\n",
        "    past_chats_text = ''\n",
        "    for history_file in chat_history_files:\n",
        "        d = load_conversation_from_json(history_file)\n",
        "        dt = d['datetime']\n",
        "        msgs = d['history']\n",
        "        msgs_str = get_buffer_string(msgs)  #, ai_prefix='あなた', human_prefix='僕')\n",
        "        past_chats_text += '【日時】 {:s}\\n{:s}\\n---\\n'.format(dt, msgs_str)\n",
        "\n",
        "    past_chat_prompt = (\n",
        "        '以下は、過去の会話です。\\n'\n",
        "        '================\\n'\n",
        "        '{:s}\\n'\n",
        "        '================\\n\\n'\n",
        "    ).format(past_chats_text.rstrip('---\\n'))\n",
        "\n",
        "    return past_chat_prompt\n",
        "\n",
        "\n",
        "past_chats_files = glob.glob('chat_history_*.json')\n",
        "past_chats_files.sort()\n",
        "past_chats_context = generate_context_from_past_chats(past_chats_files)\n",
        "print(past_chats_context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zoBOuVQwhndn"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate\n",
        ")\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "\n",
        "dt_now = '2023-07-05 19:17:28'\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    SystemMessagePromptTemplate.from_template(\n",
        "        \"あなたはエージェント型チャットボットです。\\n\"\n",
        "        \"過去の会話を参照しながら対話者（僕）と会話することができます。\\n\"\n",
        "        \"発言は、100字以内で短く返してください。\\n\\n\"\n",
        "        f\"{past_chats_context}\"\n",
        "        f\"現在の日時：{dt_now}\\n\\nそれでは、会話開始です。\"\n",
        "    ),\n",
        "    MessagesPlaceholder(variable_name=\"today_history\"),\n",
        "    HumanMessagePromptTemplate.from_template(\"{input}\")\n",
        "])\n",
        "\n",
        "def create_new_chatbot(temperature=0, verbose=True):\n",
        "    llm = ChatOpenAI(temperature=temperature, model_name=\"gpt-3.5-turbo\")\n",
        "    memory = ConversationBufferMemory(return_messages=True, memory_key='today_history')\n",
        "    chatbot = LLMChain(memory=memory, prompt=prompt, llm=llm, verbose=verbose)\n",
        "    return chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "Yy09QVt24sr-",
        "outputId": "80b14ba4-fd68-4b14-bc51-a33a7f651c27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: あなたはエージェント型チャットボットです。\n",
            "過去の会話を参照しながら対話者（僕）と会話することができます。\n",
            "発言は、100字以内で短く返してください。\n",
            "\n",
            "以下は、過去の会話です。\n",
            "================\n",
            "【日時】 2023-06-28 19:03:42\n",
            "Human: 最近暑くなってきたからさっぱりしたモノが食べたくて、冷麺を食べたよ。\n",
            "AI: いいね！ちなみに、盛岡冷麺、韓国冷麺、どっち…？\n",
            "---\n",
            "【日時】 2023-07-03 21:53:02\n",
            "Human: 今日は友達とイタリアンに行ったよ。イカスミパスタと真鯛のカルパッチョを食べたんだけど、どっちも美味しかったぁ。\n",
            "AI: いいなぁ。僕もイタリアン食べたい！！\n",
            "---\n",
            "【日時】 2023-07-04 20:11:56\n",
            "Human: 今日の昼は中華レストランでよだれ鶏を食べんたんだ。最近暑いからか、あの酸味と辛味を欲してしまうんだよね\n",
            "AI: 暑いと酸味と辛味を欲するの？なんで？\n",
            "================\n",
            "\n",
            "現在の日時：2023-07-05 19:17:28\n",
            "\n",
            "それでは、会話開始です。\n",
            "Human: 一昨日僕が食べた料理を答えてみて。\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'一昨日はイタリアンのイカスミパスタと真鯛のカルパッチョを食べたよね。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "chatbot = create_new_chatbot(verbose=True)\n",
        "chatbot.predict(input=\"一昨日僕が食べた料理を答えてみて。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ONE8Fon643aE",
        "outputId": "dc085eb3-e128-45f7-9c19-f36e895d841d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'イカスミパスタと真鯛のカルパッチョを食べたんだよね。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "chatbot = create_new_chatbot(verbose=False)\n",
        "chatbot.predict(input=\"7/3に僕が食べた料理を答えてみて。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IUr6Lhnn5eYN",
        "outputId": "b791d645-1362-4bf2-bbcf-fccce2694402"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'それは素晴らしいですね！何を作ったのか教えてください。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# 失敗例\n",
        "chatbot = create_new_chatbot(verbose=False)\n",
        "chatbot.predict(input=\"昨日食べた料理が美味しかったから、自分でも作ってみたよ。何を作ったでしょうか?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GamokYIT5j1N",
        "outputId": "55faf481-adb7-48c6-e900-c2d2ee639563"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'すみません、私は過去の会話しか覚えていませんので、昨日の料理についてはわかりません。何か他の話題でお話ししましょうか？'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# 失敗例\n",
        "chatbot = create_new_chatbot(verbose=False)\n",
        "chatbot.predict(input=\"昨日食べた料理は何でしょうか?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "grdByPF_5jOK",
        "outputId": "eca6ec95-eecc-40a0-f76a-6d11a82350d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'7/4に食べた料理は「よだれ鶏」です。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "chatbot = create_new_chatbot(verbose=False)\n",
        "chatbot.predict(input=\"7/4に食べた料理は何でしょうか？\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8waK6fXz5vhP",
        "outputId": "afa546bb-4fa2-4a47-85dd-71a08d540340"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'一週間前は、冷麺を食べたようですね。暑くなってきたからさっぱりしたモノが食べたくて、冷麺を選んだんですよ。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "chatbot = create_new_chatbot(verbose=False)\n",
        "chatbot.predict(input=\"僕、一週間前って何食べたっけ？\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5-QryDnY-eI"
      },
      "source": [
        "## 4. Agentを用いる方法\n",
        "過去の会話を、ChatBot自身で呼び出す"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0JhSWJVL7CDk"
      },
      "outputs": [],
      "source": [
        "from langchain import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0)  # text-davinci-003"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHcVNGh5ZGxP",
        "outputId": "682062bc-e2dc-48e1-d2eb-2d94acb11f4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "おととい Two days ago 2023/07/03\n",
            "2023/07/03\n"
          ]
        }
      ],
      "source": [
        "from langchain.tools import tool\n",
        "\n",
        "# 「昨日」「明日」といった単語を、日付に変更するツール\n",
        "@tool(\"get_date_from_keyword\")\n",
        "def get_date_from_keyword(date_keyward: str) -> str:\n",
        "    \"\"\"Get specific date in 'yyyy/mm/dd' format from Japanese keyword (e.g. '昨日', '明後日').\"\"\"\n",
        "    dt_today = '2023/07/05'  # Currently hard coded.\n",
        "    template1 = 'Translate japanese word \"{}\" into English.'\n",
        "    template2 = f'Today is {dt_today}. Tell the date the word \"{{}}\" means in \"2023/01/12\" format.'\n",
        "\n",
        "    word = llm(template1.format(date_keyward)).lstrip('\\n')  # 昨日 --> yesterday\n",
        "    dt_target = llm(template2.format(word)).lstrip('\\n')      # yesterday --> 2023/07/04\n",
        "    print(date_keyward, word, dt_target)\n",
        "    return dt_target\n",
        "\n",
        "print(get_date_from_keyword('おととい'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjyW-sem7K4C",
        "outputId": "f60cdbed-8ed7-4f7e-92e8-af1ed3c6769b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "以下は、2023/07/03の会話です。\n",
            "---\n",
            "Human: 今日は友達とイタリアンに行ったよ。イカスミパスタと真鯛のカルパッチョを食べたんだけど、どっちも美味しかったぁ。\n",
            "AI: いいなぁ。僕もイタリアン食べたい！！\n",
            "---\n",
            "Please recall \"New input\". Then, answer to \"New input\" based on this information.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from langchain.tools import Tool\n",
        "\n",
        "\n",
        "class RememberPastTool():\n",
        "\n",
        "    def __init__(self, chat_history_dir='./', summarize=False):\n",
        "        self._data_dir = chat_history_dir\n",
        "        self._summarize = summarize\n",
        "\n",
        "    def get_chat_history_text(self, date):\n",
        "        history_file = os.path.join(self._data_dir, f\"chat_history_{date.replace('/', '')}.json\")\n",
        "        if not os.path.isfile(history_file):\n",
        "            return 'その日は会話していないようです'\n",
        "        d = load_conversation_from_json(history_file)\n",
        "        msgs_str = get_buffer_string(d['history'])\n",
        "        return msgs_str\n",
        "\n",
        "    def remember_past(self, query: str) -> str:\n",
        "        \"\"\"Get stored past chat history. It is useful to talk about the past experience.\n",
        "        Query must be date (e.g. 2023/07/05)\"\"\"\n",
        "        query_org = query\n",
        "        if re.match(r'\\d{4}/\\d{2}/\\d{2}', query) is None:  # is not date format\n",
        "            query = get_date_from_keyword(query)\n",
        "        text = self.get_chat_history_text(query)\n",
        "        #---------------------\n",
        "        if self._summarize:\n",
        "            char_num = len(text) // 2\n",
        "            text = llm(f'以下の会話を{char_num}字以内で要約して: {text}\\n').lstrip()\n",
        "        #---------------------\n",
        "        return (f'以下は、{query_org}の会話です。\\n---\\n{text}\\n---\\n'\n",
        "                'Please recall \"New input\". Then, answer to \"New input\" based on this information.\\n')\n",
        "                # 'まず、\"New input\"を思い出してください。そして、この情報を参照して\"New input\"に回答してください。')\n",
        "\n",
        "remember_past_tool = Tool.from_function(\n",
        "    func=RememberPastTool().remember_past,\n",
        "    name=\"recall_past_chats\",\n",
        "    description=(\"MUST use this when talking about past experience. You can recall past chat conversations. \"\n",
        "                 \"Input can be date (yyyy/mm/dd) or word (e.g. '昨日', '一週間前').\")\n",
        ")\n",
        "\n",
        "print(remember_past_tool('2023/07/03'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IG-Ywt7FBGf4",
        "outputId": "1aad0ba4-0fbf-45b4-8f3d-0a5fcb3daa14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "一週間前 One week ago 2023/06/28\n",
            "以下は、一週間前の会話です。\n",
            "---\n",
            "Human: 最近暑くなってきたからさっぱりしたモノが食べたくて、冷麺を食べたよ。\n",
            "AI: いいね！ちなみに、盛岡冷麺、韓国冷麺、どっち…？\n",
            "---\n",
            "Please recall \"New input\". Then, answer to \"New input\" based on this information.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(remember_past_tool('一週間前'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IJCZ4-JR9khs"
      },
      "outputs": [],
      "source": [
        "from langchain import OpenAI\n",
        "from langchain.agents import AgentType, initialize_agent\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "\n",
        "def create_new_agent(temparature=0, verbose=True, with_initialize=False):\n",
        "    llm_chat = OpenAI(temperature=temparature)\n",
        "    memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "\n",
        "    tools = [remember_past_tool, get_date_from_keyword]\n",
        "\n",
        "    agent_chain = initialize_agent(\n",
        "        tools, llm_chat,\n",
        "        agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
        "        memory=memory,\n",
        "        verbose=verbose,\n",
        "        max_execution_time=3,   # https://python.langchain.com/docs/modules/agents/how_to/max_time_limit\n",
        "        early_stopping_method=\"generate\",\n",
        "        )\n",
        "\n",
        "    # 初期化（あまり効果はなかった）\n",
        "    if with_initialize:\n",
        "        agent_chain.run(input=(\n",
        "            \"以下はシステム入力です\\n\"\n",
        "            \"-------------\\n\"\n",
        "            \"あなたは過去の会話内容に基づいて会話をするエージェント型チャットボットです。\\n\"\n",
        "            \"以下を 【必ず】 守ってください！！\\n\"\n",
        "            \"- ユーザの発言に回答する\\n\"\n",
        "            \"- 情報が不足している場合は、正直にわからないと答える。絶対に、勝手に話を作り出さない\\n\"\n",
        "            \"- 50字以内で答える\\n\"\n",
        "            \"-------------\\n\"\n",
        "            ))\n",
        "\n",
        "    # # 内部のLLMChainの入力を見る（verbose=True）には、以下のようにする\n",
        "    # # cf. https://github.com/hwchase17/langchain/issues/912#issuecomment-1426646112\n",
        "    # agent_chain.agent.llm_chain.verbose=True\n",
        "\n",
        "    # agent_chain.agent.llm_chain.prompt.template = \\\n",
        "    #     agent_chain.agent.llm_chain.prompt.template.replace(\n",
        "    #         \"New input: {input}\",\n",
        "    #         \"New input: {input}\\n（ユーザの発言です。必ずこの発言に回答してください)\",\n",
        "    #     )\n",
        "\n",
        "    return agent_chain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_chain = create_new_agent()\n",
        "agent_chain.run(input=\"こんにちは\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "l7VozsRrxo1p",
        "outputId": "4010d3c0-489e-489d-bd70-e0e6eef7dfd0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Thought: Do I need to use a tool? No\n",
            "AI: こんにちは！どうかしましたか？\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'こんにちは！どうかしましたか？'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_chain.run(input=\"昨日は何月何日でしょうか？\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "Bry9gr9axw9d",
        "outputId": "af9bdb57-5bb9-4de4-90c9-6e194892fefe"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: get_date_from_keyword\n",
            "Action Input: 昨日\u001b[0m昨日 Yesterday 2023/07/04\n",
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3m2023/07/04\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
            "AI: 昨日は2023年7月4日です。\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'昨日は2023年7月4日です。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_chain = create_new_agent()\n",
        "agent_chain.run(input=\"一昨日、僕が何を食べたか、答えてください！\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "g9XZ0Robx32h",
        "outputId": "16bba327-0cc9-45c7-8c76-b314090c5e18"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Thought: Do I need to use a tool? Yes\n",
            "Action: recall_past_chats\n",
            "Action Input: 一昨日\u001b[0m一昨日 Two days ago 2023/07/03\n",
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3m以下は、一昨日の会話です。\n",
            "---\n",
            "Human: 今日は友達とイタリアンに行ったよ。イカスミパスタと真鯛のカルパッチョを食べたんだけど、どっちも美味しかったぁ。\n",
            "AI: いいなぁ。僕もイタリアン食べたい！！\n",
            "---\n",
            "Please recall \"New input\". Then, answer to \"New input\" based on this information.\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
            "AI: 一昨日は友達とイタリアンに行って、イカスミパスタと真鯛のカルパッチョを食べたそうですね！\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'一昨日は友達とイタリアンに行って、イカスミパスタと真鯛のカルパッチョを食べたそうですね！'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 若干微妙\n",
        "agent_chain = create_new_agent()\n",
        "agent_chain.run(input=\"僕、一週間前って何食べたっけ？\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "DtbQlb7txxZK",
        "outputId": "cc42bba9-2db5-44cd-d675-b3b66b99d5e9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Thought: Do I need to use a tool? Yes\n",
            "Action: recall_past_chats\n",
            "Action Input: one week ago\u001b[0mone week ago One Week Ago 2023/06/28\n",
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3m以下は、one week agoの会話です。\n",
            "---\n",
            "Human: 最近暑くなってきたからさっぱりしたモノが食べたくて、冷麺を食べたよ。\n",
            "AI: いいね！ちなみに、盛岡冷麺、韓国冷麺、どっち…？\n",
            "---\n",
            "Please recall \"New input\". Then, answer to \"New input\" based on this information.\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
            "AI: 冷麺なら、盛岡冷麺と韓国冷麺がありますね！どちらを食べましたか？\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'冷麺なら、盛岡冷麺と韓国冷麺がありますね！どちらを食べましたか？'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 若干微妙\n",
        "agent_chain = create_new_agent()\n",
        "agent_chain.run(input=\"昨日僕が食べた料理を答えてみて。\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "1EieUJizx9BP",
        "outputId": "bcdd339e-14e9-47d8-e99e-b31026003251"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Thought: Do I need to use a tool? Yes\n",
            "Action: recall_past_chats\n",
            "Action Input: 昨日\u001b[0m昨日 Yesterday 2023/07/04\n",
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3m以下は、昨日の会話です。\n",
            "---\n",
            "Human: 今日の昼は中華レストランでよだれ鶏を食べんたんだ。最近暑いからか、あの酸味と辛味を欲してしまうんだよね\n",
            "AI: 暑いと酸味と辛味を欲するの？なんで？\n",
            "---\n",
            "Please recall \"New input\". Then, answer to \"New input\" based on this information.\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
            "AI: 昨日は中華レストランでよだれ鶏を食べましたね。暑いからか、あの酸味と辛味がとても美味しかったです。\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'昨日は中華レストランでよだれ鶏を食べましたね。暑いからか、あの酸味と辛味がとても美味しかったです。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 失敗例\n",
        "agent_chain = create_new_agent()\n",
        "agent_chain.run(input=\"一昨日の日付は？その日、僕が食べた料理は何？\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "3zlzlxZfzRfi",
        "outputId": "4ad621f1-48a3-47bb-cad0-0b202b79b54b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Thought: Do I need to use a tool? Yes\n",
            "Action: get_date_from_keyword\n",
            "Action Input: 一昨日\u001b[0m一昨日 Two days ago 2023/07/03\n",
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3m2023/07/03\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
            "AI: 一昨日は2023年7月3日ですね。その日は、あなたが食べた料理は何でしたか？\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'一昨日は2023年7月3日ですね。その日は、あなたが食べた料理は何でしたか？'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent_chain.agent.llm_chain.prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12LBkgLFya5l",
        "outputId": "6b87349f-b46d-41da-f360-a16e887b962f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assistant is a large language model trained by OpenAI.\n",
            "\n",
            "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
            "\n",
            "TOOLS:\n",
            "------\n",
            "\n",
            "Assistant has access to the following tools:\n",
            "\n",
            "> recall_past_chats: MUST use this when talking about past experience. You can recall past chat conversations. Input can be date (yyyy/mm/dd) or word (e.g. '昨日', '一週間前').\n",
            "> get_date_from_keyword: get_date_from_keyword(date_keyward: str) -> str - Get specific date in 'yyyy/mm/dd' format from Japanese keyword (e.g. '昨日', '明後日').\n",
            "\n",
            "To use a tool, please use the following format:\n",
            "\n",
            "```\n",
            "Thought: Do I need to use a tool? Yes\n",
            "Action: the action to take, should be one of [recall_past_chats, get_date_from_keyword]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "```\n",
            "\n",
            "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
            "\n",
            "```\n",
            "Thought: Do I need to use a tool? No\n",
            "AI: [your response here]\n",
            "```\n",
            "\n",
            "Begin!\n",
            "\n",
            "Previous conversation history:\n",
            "{chat_history}\n",
            "\n",
            "New input: {input}\n",
            "{agent_scratchpad}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "syh2FxFDZ2UY"
      },
      "execution_count": 25,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}